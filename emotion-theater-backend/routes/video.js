const express = require("express");
const router = express.Router();
const { AzureOpenAI } = require("openai");
const axios = require("axios");
const ffmpeg = require("fluent-ffmpeg");
const fs = require("fs");
const path = require("path");

// âœ… [ìˆ˜ì •] í™˜ê²½ì— ë”°ë¼ ffmpeg ê²½ë¡œ ì„¤ì •
// Windows ë¡œì»¬ í™˜ê²½: í”„ë¡œì íŠ¸ ë‚´ë¶€ì˜ ffmpeg.exe ì‚¬ìš©
// Azure Linux í™˜ê²½: ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ ffmpeg ì‚¬ìš©
const isWindows = process.platform === 'win32';
const isAzure = process.env.WEBSITE_INSTANCE_ID !== undefined; // Azure í™˜ê²½ ê°ì§€

if (isWindows && !isAzure) {
  // Windows ë¡œì»¬ ê°œë°œ í™˜ê²½
  const ffmpegPath = path.join(__dirname, '..', 'bin', 'ffmpeg.exe');
  const ffprobePath = path.join(__dirname, '..', 'bin', 'ffprobe.exe');
  ffmpeg.setFfmpegPath(ffmpegPath);
  ffmpeg.setFfprobePath(ffprobePath);
  console.log('[Video] Windows í™˜ê²½: ë¡œì»¬ ffmpeg.exe ì‚¬ìš©');
} else {
  // Azure Linux í™˜ê²½ ë˜ëŠ” ê¸°íƒ€ Unix í™˜ê²½: ì‹œìŠ¤í…œ ffmpeg ì‚¬ìš©
  console.log('[Video] Linux/Azure í™˜ê²½: ì‹œìŠ¤í…œ ffmpeg ì‚¬ìš©');
}

const {
  storiesContainer,
  settingsContainer,
  DEFAULT_IMAGE_PROMPT_SYSTEM,
} = require("../db");

// âœ… [ìˆ˜ì •] í…ìŠ¤íŠ¸ ìƒì„±ìš©(GPT) OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const textClient = new AzureOpenAI({
  endpoint: process.env.AZURE_OPENAI_ENDPOINT,
  apiKey: process.env.AZURE_OPENAI_KEY,
  apiVersion: process.env.AZURE_OPENAI_API_VERSION,
  timeout: 180000,
});

// âœ… [ìˆ˜ì •] ì´ë¯¸ì§€ ìƒì„±ìš©(DALL-E) OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const dalleClient = new AzureOpenAI({
  endpoint: process.env.AZURE_OPENAI_DALLE_ENDPOINT,
  apiKey: process.env.AZURE_OPENAI_DALLE_KEY,
  apiVersion: process.env.AZURE_OPENAI_DALLE_API_VERSION,
  timeout: 180000,
});

// ì„ì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
const TEMP_DIR = path.join(__dirname, "../temp");
const VIDEOS_DIR = path.join(__dirname, "../videos");

// ë””ë ‰í† ë¦¬ ìƒì„±
if (!fs.existsSync(TEMP_DIR)) fs.mkdirSync(TEMP_DIR, { recursive: true });
if (!fs.existsSync(VIDEOS_DIR)) fs.mkdirSync(VIDEOS_DIR, { recursive: true });

// ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
async function downloadImage(url, filepath, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const response = await axios({
        url,
        method: "GET",
        responseType: "stream",
        timeout: 30000, // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
      });
      return new Promise((resolve, reject) => {
        const writer = fs.createWriteStream(filepath);
        response.data.pipe(writer);
        writer.on("finish", resolve);
        writer.on("error", reject);
      });
    } catch (error) {
      console.log(`[VIDEO] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„ ${attempt}/${retries} ì‹¤íŒ¨: ${error.message}`);
      if (attempt === retries) {
        throw error; // ë§ˆì§€ë§‰ ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
      }
      // ì¬ì‹œë„ ì „ 2ì´ˆ ëŒ€ê¸°
      await new Promise(resolve => setTimeout(resolve, 2000));
    }
  }
}

// âœ… XML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ í•¨ìˆ˜
function escapeXml(text) {
  return text
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&apos;');
}

// âœ… [ì¶”ê°€] ê°ì • í‘œí˜„ì„ ìœ„í•œ SSML íƒœê·¸ ì¶”ê°€ í•¨ìˆ˜
function addEmotionToText(text) {
  // ë¨¼ì € í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„
  const escapedText = escapeXml(text);

  let processedText = escapedText;

  // ê°íƒ„ì‚¬ íŒ¨í„´ (ì™€!, ì–´ë¨¸!, ì•—!, í—‰!, ì˜¤!, ìš°ì™€! ë“±)
  const exclamations = /(ì™€|ìš°ì™€|ì–´ë¨¸|ì•—|í—‰|ì˜¤|ì•„|ì•¼|ì´ëŸ°|ëŒ€ë‹¨í•´|ë©‹ì ¸|ì¢‹ì•„|ì‹ ë‚˜|ìµœê³ )(!+)/gi;

  // ëŠë‚Œí‘œë¡œ ëë‚˜ëŠ” ë¬¸ì¥ (ê°•ì¡°)
  const exclamationSentence = /([^<>\n]+!+)/g;

  // ë¬¼ìŒí‘œë¡œ ëë‚˜ëŠ” ë¬¸ì¥ (ì˜ë¬¸)
  const questionSentence = /([^<>\n]+\?+)/g;

  // ë§ì¤„ì„í‘œ (ëŠë¦¬ê²Œ)
  const ellipsis = /(\.\.\.+|â€¦)/g;

  // 1. ê°íƒ„ì‚¬ì— ê°•í•œ ê°ì • ì¶”ê°€
  processedText = processedText.replace(exclamations, (match) => {
    return `<emphasis level="strong"><prosody pitch="+15%" rate="1.1">${match}</prosody></emphasis>`;
  });

  // 2. ëŠë‚Œí‘œ ë¬¸ì¥ì— í™œê¸°ì°¬ í†¤ ì¶”ê°€ (ê°íƒ„ì‚¬ ì œì™¸)
  processedText = processedText.replace(exclamationSentence, (match) => {
    // ì´ë¯¸ ì²˜ë¦¬ëœ emphasis íƒœê·¸ê°€ ìˆìœ¼ë©´ ê±´ë„ˆëœ€
    if (match.includes('emphasis') || match.includes('prosody')) return match;
    return `<prosody pitch="+8%" rate="1.05">${match}</prosody>`;
  });

  // 3. ë¬¼ìŒí‘œ ë¬¸ì¥ì— ì˜ë¬¸ í†¤ ì¶”ê°€
  processedText = processedText.replace(questionSentence, (match) => {
    // ì´ë¯¸ ì²˜ë¦¬ëœ íƒœê·¸ê°€ ìˆìœ¼ë©´ ê±´ë„ˆëœ€
    if (match.includes('prosody')) return match;
    return `<prosody pitch="+5%">${match}</prosody>`;
  });

  // 4. ë§ì¤„ì„í‘œì— ëŠë¦° ì†ë„ ì¶”ê°€
  processedText = processedText.replace(ellipsis, (match) => {
    return `<break time="300ms"/><prosody rate="0.85">${match}</prosody><break time="300ms"/>`;
  });

  return processedText;
}

// âœ… [ìˆ˜ì •] í™”ìë³„ ìŒì„±ì„ ë‹¤ë¥´ê²Œ ì ìš©í•˜ì—¬ SSML ê¸°ë°˜ TTS ìƒì„±
// í™”ì ì´ë¦„(ë‚˜ë ˆì´í„°:, ì—„ë§ˆ:, ì•„ë¹ : ë“±)ì€ ì½ì§€ ì•Šê³ , ëŒ€ì‚¬ë§Œ ì½ìŠµë‹ˆë‹¤.
async function generateSceneTTS(text, characterName, voicePref) {
  const sdk = require("microsoft-cognitiveservices-speech-sdk");
  const speechConfig = sdk.SpeechConfig.fromSubscription(
    process.env.AZURE_SPEECH_KEY,
    process.env.AZURE_SPEECH_REGION
  );

  console.log(`[TTS] generateSceneTTS í˜¸ì¶œë¨ - voicePref: ${voicePref}, characterName: ${characterName}`);

  // âœ… í™”ìë³„ ìŒì„± ë§¤í•‘
  const voiceMap = {
    'ë‚˜ë ˆì´í„°': voicePref === 'male' ? 'ko-KR-InJoonNeural' : 'ko-KR-SunHiNeural',
    'ì—„ë§ˆ': 'ko-KR-SunHiNeural',
    'ì•„ë¹ ': 'ko-KR-InJoonNeural',
    'í• ë¨¸ë‹ˆ': 'ko-KR-SoonBokNeural',
    'í• ì•„ë²„ì§€': 'ko-KR-InJoonNeural',
    // ë™ë¬¼/ì¡°ì—° ìºë¦­í„°ë“¤
    'í† ë¼': 'ko-KR-SeoHyeonNeural', // ë°ê³  ê·€ì—¬ìš´ ëª©ì†Œë¦¬
    'ë‹¤ëŒì¥': 'ko-KR-SeoHyeonNeural',
    'ìƒˆ': 'ko-KR-JiMinNeural',
    'ê³°': 'ko-KR-BongJinNeural',
    'ë¶€ì—‰ì´': 'ko-KR-InJoonNeural',
    'ì¹œêµ¬': voicePref === 'male' ? 'ko-KR-GookMinNeural' : 'ko-KR-JiMinNeural',
    'ì„ ìƒë‹˜': 'ko-KR-SunHiNeural',
  };

  // âœ… [ìˆ˜ì •] í…ìŠ¤íŠ¸ë¥¼ í™”ìë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ SSML ìƒì„±
  const lines = text.split('\n').filter(line => line.trim());
  let ssml = '<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">';

  for (const line of lines) {
    // "í™”ì: ëŒ€ì‚¬" í˜•ì‹ì¸ì§€ í™•ì¸
    const match = line.match(/^([^:]+):\s*(.+)$/);
    if (match) {
      const speaker = match[1].trim(); // í™”ì ì´ë¦„ (ì½ì§€ ì•ŠìŒ)
      const dialogue = match[2].trim(); // ëŒ€ì‚¬ë§Œ ì¶”ì¶œ (ì´ê²ƒë§Œ ì½ìŒ)

      // í™”ìì— ë§ëŠ” ìŒì„± ì„ íƒ
      let voice = voiceMap[speaker];
      if (!voice) {
        // ì£¼ì¸ê³µ ì´ë¦„ì¼ ê°€ëŠ¥ì„±
        if (speaker === characterName) {
          voice = voicePref === 'male' ? 'ko-KR-GookMinNeural' : 'ko-KR-JiMinNeural';
        } else {
          // ê¸°ë³¸ ìŒì„±
          voice = voicePref === 'male' ? 'ko-KR-InJoonNeural' : 'ko-KR-SunHiNeural';
        }
      }

      // âœ… ì¤‘ìš”: dialogueë§Œ SSMLì— í¬í•¨ (í™”ì ì´ë¦„ì€ ì œì™¸)
      // âœ… [ì¶”ê°€] ê°ì • í‘œí˜„ ì¶”ê°€
      const emotionalDialogue = addEmotionToText(dialogue);
      console.log(`[TTS] í™”ì: "${speaker}" â†’ ìŒì„±: ${voice}, ëŒ€ì‚¬: "${dialogue.substring(0, 30)}..."`);
      ssml += `<voice name="${voice}">${emotionalDialogue}</voice>`;
    } else {
      // í™”ì ì—†ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ë‚˜ë ˆì´í„° ìŒì„±ìœ¼ë¡œ
      const narratorVoice = voicePref === 'male' ? 'ko-KR-InJoonNeural' : 'ko-KR-SunHiNeural';
      const emotionalLine = addEmotionToText(line);
      console.log(`[TTS] í™”ì ì—†ìŒ â†’ ë‚˜ë ˆì´í„° ìŒì„±: ${narratorVoice}, í…ìŠ¤íŠ¸: "${line.substring(0, 30)}..."`);
      ssml += `<voice name="${narratorVoice}">${emotionalLine}</voice>`;
    }
  }

  ssml += '</speak>';

  console.log(`[TTS] SSML ìƒì„± ì™„ë£Œ (í™”ì ì´ë¦„ ì œê±°ë¨), voicePref=${voicePref}`);

  return new Promise((resolve, reject) => {
    const synthesizer = new sdk.SpeechSynthesizer(speechConfig, null);
    synthesizer.speakSsmlAsync(
      ssml,
      (result) => {
        if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
          synthesizer.close();
          resolve(Buffer.from(result.audioData));
        } else {
          synthesizer.close();
          reject(new Error("TTS failed: " + result.errorDetails));
        }
      },
      (error) => {
        synthesizer.close();
        reject(error);
      }
    );
  });
}

// ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ë¥¼ ë™ì˜ìƒìœ¼ë¡œ ë³€í™˜
// âœ… [ìˆ˜ì •] ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ë™ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤ (duration íŒŒë¼ë¯¸í„° ì œê±°)
function createVideoFromImageAndAudio(imagePath, audioPath, outputPath) {
  return new Promise((resolve, reject) => {
    ffmpeg()
      .input(imagePath)
      .inputOptions('-noautorotate') // âœ… [ì¬í™•ì¸] ì´ë¯¸ì§€ì˜ ìë™ íšŒì „ì„ ë°©ì§€í•©ë‹ˆë‹¤.
      .loop() // ì´ë¯¸ì§€ë¥¼ ë¬´í•œ ë°˜ë³µ (-shortest ì˜µì…˜ì´ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ìë¦„)
      .input(audioPath)
      .outputOptions([
        "-c:v libx264",
        "-tune stillimage",
        "-c:a aac",
        "-b:a 192k",
        "-pix_fmt yuv420p",
        "-shortest", // ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ë™ì˜ìƒ ìƒì„±
      ])
      .output(outputPath)
      .on("end", () => resolve())
      .on("error", (err) => reject(err))
      .run();
  });
}

// ì—¬ëŸ¬ ë™ì˜ìƒì„ í•˜ë‚˜ë¡œ ê²°í•©
function concatenateVideos(videoPaths, outputPath) {
  return new Promise((resolve, reject) => {
    const listFile = path.join(TEMP_DIR, `concat_${Date.now()}.txt`);
    const listContent = videoPaths.map((p) => `file '${p}'`).join("\n");
    fs.writeFileSync(listFile, listContent);

    ffmpeg()
      .input(listFile)
      .inputOptions(["-f concat", "-safe 0"])
      .outputOptions(["-c copy"])
      .output(outputPath)
      .on("end", () => {
        fs.unlinkSync(listFile);
        resolve();
      })
      .on("error", (err) => {
        if (fs.existsSync(listFile)) fs.unlinkSync(listFile);
        reject(err);
      })
      .run();
  });
}

// âœ… [ì¶”ê°€] ë™ì˜ìƒ ìƒì„± ë¡œì§ì„ ë³„ë„ ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë¶„ë¦¬
async function processVideoGeneration(story, userData, videoId, tempDir, userToken) { // userToken ì¸ì ì¶”ê°€
  // âœ… [ìˆ˜ì •] voicePrefì— ê¸°ë³¸ê°’ ì„¤ì • (undefined ë°©ì§€)
  const voicePref = userData.voicePref || 'female';

  try {
    console.log("[VIDEO] ë™ì˜ìƒ ìƒì„± ì‹œì‘:", videoId);
    console.log("[VIDEO] ì‚¬ìš©í•  ìŒì„± ì„¤ì •:", voicePref);

    // âœ… [ìˆ˜ì •] 1. /api/stories/generate-video-scenes ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¥ë©´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    // ì´ í˜¸ì¶œì€ ì„œë²„ ë‚´ë¶€ì—ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
    console.log("[VIDEO] ì¥ë©´ ë¶„í•  ë° ì‚½í™” í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤...");
    const sceneResponse = await axios.post(
      `http://localhost:${process.env.PORT || 4000}/api/stories/generate-video-scenes`,
      {
        story,
        userData, // âœ… [ìˆ˜ì •] userData ê°ì²´ ì „ì²´ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
      },
      { // âœ… [ìˆ˜ì •] Authorization í—¤ë” ì¶”ê°€
        headers: {
          'Content-Type': 'application/json',
          'Authorization': userToken // í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ì€ í† í°ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
        },
        timeout: 300000, // ë‚´ë¶€ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ 5ë¶„
      }
    );
    const scenes = sceneResponse.data.scenes;
    console.log(`[VIDEO] ${scenes.length}ê°œ ì¥ë©´ ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ`);

    // 2. ê° ì¥ë©´ë³„ ì²˜ë¦¬
    let imagePromptSystem = DEFAULT_IMAGE_PROMPT_SYSTEM;
    try {
      const { resource: imagePromptSetting } = await settingsContainer.item("imagePromptSystem", "prompt").read();
      if (imagePromptSetting) imagePromptSystem = imagePromptSetting.value;
    } catch (e) {
      console.log("[Prompt] DBì— ì €ì¥ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.");
    }

    const sceneVideos = [];

    for (let i = 0; i < scenes.length; i++) {
      const scene = scenes[i];
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} ì²˜ë¦¬ ì¤‘...`);
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} í…ìŠ¤íŠ¸ ë‚´ìš© (ì²˜ìŒ 200ì):`);
      console.log(scene.text.substring(0, 200));
      console.log('---');

      // âœ… [ìˆ˜ì •] 2-1. ì´ë¯¸ ìƒì„±ëœ ì‚½í™” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
      const imagePrompt = scene.imagePrompt || "A beautiful fairy tale scene";
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} DALL-E í”„ë¡¬í”„íŠ¸:`, imagePrompt);

      let imageUrl;
      try {
        // âœ… [ìˆ˜ì •] DALL-E ì´ë¯¸ì§€ ìƒì„±
        const imageResponse = await dalleClient.images.generate({
          model: process.env.AZURE_OPENAI_DEPLOYMENT_IMAGE,
          prompt: imagePrompt,
          n: 1,
          size: "1792x1024", // âœ… [ìˆ˜ì •] ê°€ë¡œ ë¹„ìœ¨(16:9)ë¡œ ë³€ê²½í•˜ì—¬ íšŒì „ ë¬¸ì œ ë°©ì§€
          quality: "standard",
        });
        imageUrl = imageResponse.data[0].url;
        console.log(`[VIDEO] ì¥ë©´ ${scene.scene} DALL-E ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ`);
      } catch (error) {
        // âœ… [ì¶”ê°€] ì½˜í…ì¸  ì •ì±… ìœ„ë°˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ, ì•ˆì „í•œ ëŒ€ì²´ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.
        if (error.code === 'content_policy_violation') {
          console.warn(`[VIDEO] ì¥ë©´ ${scene.scene}ì˜ í”„ë¡¬í”„íŠ¸ê°€ ì½˜í…ì¸  ì •ì±…ì— ìœ„ë°˜ë˜ì–´ ëŒ€ì²´ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.`);
          const safeImagePrompt = "A beautiful and safe illustration for a children's fairy tale, gentle and heartwarming style, simple background.";
          const imageResponse = await dalleClient.images.generate({
            model: process.env.AZURE_OPENAI_DEPLOYMENT_IMAGE,
            prompt: safeImagePrompt,
            n: 1,
            size: "1792x1024", // âœ… [ìˆ˜ì •] ê°€ë¡œ ë¹„ìœ¨(16:9)ë¡œ ë³€ê²½í•˜ì—¬ íšŒì „ ë¬¸ì œ ë°©ì§€
            quality: "standard",
          });
          imageUrl = imageResponse.data[0].url;
          console.log(`[VIDEO] ì¥ë©´ ${scene.scene} ëŒ€ì²´ í”„ë¡¬í”„íŠ¸ë¡œ DALL-E ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ`);
        } else {
          throw error; // ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
        }
      }

      // 2-2. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
      const imagePath = path.join(tempDir, `scene_${scene.scene}.jpg`);
      await downloadImage(imageUrl, imagePath);
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ`);

      // âœ… [ìˆ˜ì •] í™”ìë³„ ìŒì„±ì„ ì ìš©í•˜ì—¬ TTS ìƒì„±
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} TTS ìƒì„± ì‹œì‘ (voicePref: ${voicePref})`);
      const audioBuffer = await generateSceneTTS(scene.text, userData.name, voicePref);
      const audioPath = path.join(tempDir, `scene_${scene.scene}.wav`);
      fs.writeFileSync(audioPath, audioBuffer);
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} TTS ìƒì„± ì™„ë£Œ (í™”ìë³„ ìŒì„± ì ìš©, voicePref: ${voicePref})`);

      // 2-4. ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ -> ë¹„ë””ì˜¤ ìƒì„±
      const videoPath = path.join(tempDir, `scene_${scene.scene}.mp4`);
      // âœ… [ìˆ˜ì •] ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ë™ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤
      await createVideoFromImageAndAudio(imagePath, audioPath, videoPath);
      sceneVideos.push(videoPath);
      console.log(`[VIDEO] ì¥ë©´ ${scene.scene} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ`);
    }

    // 3. ëª¨ë“  ì¥ë©´ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ê²°í•©
    console.log("[VIDEO] ëª¨ë“  ì¥ë©´ì„ í•˜ë‚˜ì˜ ë™ì˜ìƒìœ¼ë¡œ ê²°í•© ì¤‘...");
    const finalVideoPath = path.join(VIDEOS_DIR, `${videoId}.mp4`);
    await concatenateVideos(sceneVideos, finalVideoPath);

    // 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬
    fs.rmSync(tempDir, { recursive: true, force: true });

    console.log("[VIDEO] ìµœì¢… ë™ì˜ìƒ ìƒì„± ì„±ê³µ:", videoId);

  } catch (error) {
    console.error("âŒ [ì˜¤ë¥˜] ë™ì˜ìƒ ìƒì„± ì‹¤íŒ¨:", error);
    if (error.code) console.error("ì—ëŸ¬ ì½”ë“œ:", error.code);
    if (error.message) console.error("ì—ëŸ¬ ë©”ì‹œì§€:", error.message);

    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }

    // ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì´ë¯€ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µì„ ë³´ë‚¼ ìˆ˜ ì—†ìŒ. ì½˜ì†”ì— ì—ëŸ¬ ê¸°ë¡.
    console.error(`[ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë¥˜] videoId ${videoId} ìƒì„± ì‹¤íŒ¨:`, error.message);
  }
}

// [POST] /api/video/generate - ë™ì˜ìƒ ìƒì„± ìš”ì²­ ì ‘ìˆ˜
router.post("/generate", async (req, res) => {
  const { story, userData } = req.body;

  if (!story || !userData || !userData.name || !userData.emotion) {
    return res.status(400).json({ message: "ë™í™” ë‚´ìš©, ì´ë¦„, ê°ì •ì€ í•„ìˆ˜ì…ë‹ˆë‹¤." });
  }

  const videoId = `video_${Date.now()}`;
  const tempDir = path.join(TEMP_DIR, videoId);
  fs.mkdirSync(tempDir, { recursive: true });

  // âœ… [ìˆ˜ì •] í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì¦‰ì‹œ ì‘ë‹µì„ ë³´ëƒ…ë‹ˆë‹¤.
  res.status(202).json({
    success: true,
    message: "ë™ì˜ìƒ ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ì•Œë¦¼ì´ í‘œì‹œë©ë‹ˆë‹¤.",
    videoId: videoId,
  });

  // âœ… [ìˆ˜ì •] ì‘ë‹µì„ ë³´ë‚¸ í›„, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë™ì˜ìƒ ìƒì„± ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
  // 'await'ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ìš”ì²­-ì‘ë‹µ ì‚¬ì´í´ì„ ì°¨ë‹¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  processVideoGeneration(story, userData, videoId, tempDir, req.headers.authorization).catch(error => { // userToken ì „ë‹¬
    // âœ… [ìˆ˜ì •] ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤íŒ¨ ì‹œ ë” ìƒì„¸í•œ ì—ëŸ¬ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
    console.error(`ğŸš¨ [ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë¥˜] videoId ${videoId} ìƒì„± ì‹¤íŒ¨:`, error.message);
    if (error.stack) console.error(error.stack);

    // ì—¬ê¸°ì„œ ì‹¤íŒ¨í•˜ë”ë¼ë„ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì‘ë‹µì„ ë³´ë‚¼ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¡œê·¸ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
  });
});

// [GET] /api/video/status/:videoId - ë™ì˜ìƒ ìƒì„± ìƒíƒœ í™•ì¸
router.get("/status/:videoId", (req, res) => {
  const { videoId } = req.params;
  const videoPath = path.join(VIDEOS_DIR, `${videoId}.mp4`);

  // ë³´ì•ˆ ê²€ì‚¬: videoId í˜•ì‹ì´ ë§ëŠ”ì§€ í™•ì¸
  if (!videoId.startsWith('video_') || !/^[a-zA-Z0-9_]+$/.test(videoId)) {
    return res.status(400).json({ message: "ì˜ëª»ëœ ë™ì˜ìƒ ID í˜•ì‹ì…ë‹ˆë‹¤." });
  }

  // íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì™„ë£Œ, ì—†ìœ¼ë©´ ì§„í–‰ ì¤‘
  if (fs.existsSync(videoPath)) {
    return res.status(200).json({
      status: "completed",
      videoId: videoId,
      downloadUrl: `/api/video/download/${videoId}`
    });
  } else {
    return res.status(200).json({
      status: "processing",
      videoId: videoId
    });
  }
});

// [GET] /api/video/download/:videoId - ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ
router.get("/download/:videoId", (req, res) => {
  const { videoId } = req.params;
  const videoPath = path.join(VIDEOS_DIR, `${videoId}.mp4`);

  // âœ… [ì¶”ê°€] ê°„ë‹¨í•œ ë³´ì•ˆ ê²€ì‚¬: videoId í˜•ì‹ì´ ë§ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
  if (!videoId.startsWith('video_') || !/^[a-zA-Z0-9_]+$/.test(videoId)) {
    return res.status(400).json({ message: "ì˜ëª»ëœ ë™ì˜ìƒ ID í˜•ì‹ì…ë‹ˆë‹¤." });
  }

  if (!fs.existsSync(videoPath)) {
    return res.status(404).json({ message: "ë™ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." });
  }

  res.download(videoPath, `fairytale_${videoId}.mp4`, (err) => {
    if (err) {
      console.error("ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜:", err);
      res.status(500).json({ message: "ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." });
    }
  });
});

module.exports = router;
